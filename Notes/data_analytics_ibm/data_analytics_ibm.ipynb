{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera IBM / Data Analytics Notebook\n",
    "\n",
    "## Some extracts\n",
    "- \"Businesses today recognize the untapped value in data and data analytics as a crucial factor for business competitiveness. To drive their data and analytics initiatives, companies are hiring and upskilling people. They are expanding their teams and creating centers of excellence to set up a multi-pronged data and analytics practice in their organizations.\" \n",
    "    - (a Forrester Report) \n",
    "    - (The Power of Data to Transform Your Business)\n",
    "\n",
    "\n",
    "* \"The constant increase in data processing speeds and bandwidth, the nonstop invention of new tools for creating, sharing and consuming data, and the steady addition of new data creators and consumers around the world, ensure that data growth continues unabated. Data begets more data in a constant virtuous cycle.\"\n",
    "    - (a Forbes 2020 Report)\n",
    "\n",
    "* Report Conclusions: \t\n",
    "    - data -> data -> data. Data cycle\n",
    "    - Data holds the key to competitive advantage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytics Jobs and their responsibilities:\n",
    "1) Data Engineer -> \n",
    "\t- build and maintain data architectures, make data available for others\n",
    "\t- accessible data for APP's.\n",
    "\t\n",
    "2) Data Analyst:\n",
    "\t- translates data and numbers into plain language\n",
    "\t- inspects/cleans data\n",
    "\t- identifies PATTERNS, mines data\n",
    "\t- VISUALIZES data\n",
    "\t    - REMARK: data translating, inspecting, cleaning, identifying, mining, visualizing\n",
    "\t\n",
    "\n",
    "3) Data Scientists:\n",
    "\t- analyze data for actionable insights\n",
    "\t- create predictive models for ML / DL \n",
    "\t- PREDICTIONS for customers\n",
    "\t- math, statistics, domain knowledge, programming\n",
    "\t    - REMARK: transform data into predictions and models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) BI Analysts:\n",
    "\t- leverage the work of Data Analysts and Scientists \n",
    "\t\t- to look at possible implications for their business and \n",
    "\t\t  the actions they need to take or recommend\n",
    "\n",
    "### Remarks:\t\t\n",
    "1) Data Engineering: \n",
    "\t- converts raw data into usable data\n",
    "2) Data Analysts: \n",
    "\t- use this data to generate insights\n",
    "3) Data Scientists: \n",
    "\t- use Data Analytics and Data Engineering to \n",
    "\t\t- PREDICT the future using data from the past, \n",
    "\t\t- make MODELS\n",
    "4) Business Analysts and Business Intelligence (BI) Analysts: \n",
    "\t- use these insights and predictions to drive decisions that \n",
    "\t\t- BENEFIT and grow their BUSINESS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Data Analysis?\n",
    "* DATA ANALYSIS:\n",
    "\t- gather, clean, analyze, mine data\n",
    "\t- interpret results\n",
    "\t- report the findings\n",
    "\t- find patterns/correlations within data to generate insights, conclusions\n",
    "\t\n",
    "\t- understand past perf\n",
    "\t- take informed decisions\n",
    "\t- validate course of action b4 committing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Data Analysis:\t\n",
    "* 4 TYPES:\n",
    "\t1) Descriptive Analytics: \n",
    "\t\t- \"what happened\"\n",
    "\t\t- provides insights to past events\n",
    "\t2) Diagnostic Analytics: \n",
    "\t\t- \"why did it happen\"\n",
    "\t\t- takes insights from g<1> to dig deeper\n",
    "\t3) Predictive Analysis: \n",
    "\t\t- \"what will happen next\"\n",
    "\t\t- leverages historical data and trends to predict future outcomes\n",
    "\t4) Prescriptive Analytics: \n",
    "\t\t- \"what should be done about it\"\n",
    "\t\t- analyzes past events to estimate the likelihood of different outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis Process:\t\t\n",
    "* PROCESS:\n",
    "\t1) Understanding the problem, desired outcome\n",
    "\t2) Setting a clear metric, what and how should it be measured.\n",
    "\t3) Gathering data, identify data you req, best tools, best sources for data\n",
    "\t4) Cleaning data: fixing quality issues in data, standardize data coming from multiple sources.\n",
    "\t5) Analyzing and Mining data:\n",
    "\t\t- extract, analyze, manipulate data from different perspectives to understand trends, find patterns\n",
    "\t6) Interpreting results:\n",
    "\t\t- evaluating defendability of analysis \n",
    "\t7) Presenting your findings:\n",
    "\t\t- communicate, present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks:\n",
    "* Remarks of Process\t\t\n",
    "\t- understand problem, wanted outcome.\n",
    "\t- what and how, \n",
    "\t- gather, identify data, best tools? best sources?\n",
    "\t- clean - standardization, fixes\n",
    "\t- analyze, mine, extract, manipulate data - understand trends, find patterns\n",
    "\t- interpret, present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remarks of Data Analytics:\n",
    "\n",
    "\t- Collecting, analyzing data/info\n",
    "\t- Confirm Hypo\n",
    "\t- Storytelling with Data\n",
    "\n",
    "\t- Use of info to make decisions\n",
    "\n",
    "\t- Define the problem, create hypothesis, collect/clean data to test, analyze data, present.\n",
    "\n",
    "\t- analyze sets of data to understand what's going on.\n",
    "\n",
    "\t- understand where a business is coming from, it's present and predict its future decisions\n",
    "\n",
    "\t- Analyze, present, share data. To communicate business insights, help make better decisions.\n",
    "\n",
    "\t- Process of gathering info from relevant population. Breaking that info into subsets (cluster probability), using that data to make decisions, predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remarks of responsibilities of data analysts:\n",
    "\t- acquiring data\n",
    "\t- creating queries to extract data\n",
    "\t- filtering, cleaning, standardizing, reorganizing data\n",
    "\t- using statistical techniques (visualization, ggplot2, R)\n",
    "\t- analyze patterns, trends\n",
    "\t- prepare reports\n",
    "\t- create approp. docs\n",
    "\n",
    "\t\t- acquire, prepare, analyze data. Interpret, communicate, doc.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State differences between data analytics and data analysis, in the POV of statistics.\n",
    "* Data Analytics vs. Data Analysis:\n",
    "\t- they are often used interchangeably.\n",
    "\t\t- however there is a subtle diff.\n",
    "\t\n",
    "\t- Analysis - detailed exam of the elements or structure of sth\n",
    "\t- Analytics - the systematic computational analysis of data or statistics\n",
    "\t* NOTE: for data and statistics POV, they are about same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Skills:\n",
    "- natural curiosity\n",
    "- attention to detailed, looking for patterns\n",
    "\n",
    "- Py, SQL, R, Tableau, Power BI\n",
    "\n",
    "+ Sales pipeline analysis\n",
    "+ financial reporting\n",
    "+ headcount planning\n",
    "+ all verticals, such as Airlines, Pharmas, Banks.\n",
    "\n",
    "\t\n",
    "\n",
    "\t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: \n",
    "### General Info:\n",
    "* Structured (databases, datasets) \n",
    "\t- tabular manner - rows, columns\n",
    "\t- SQL databases\n",
    "\t- OTP (online transaction processing)\n",
    "\t- GPS, RFID tags\n",
    "\t- network-web server logs\n",
    "\t- online forms/spreadsheets\n",
    "\n",
    "* Semi-structured \n",
    "\t- tags, elements (metadata)\n",
    "\t- groups data to hierarchy\n",
    "\t\t* e-mails\n",
    "\t\t* binary exe's\n",
    "\t\t* .zip\n",
    "\t\t* XMLs, JSONs\n",
    "* Unstructured (photos, pdfs, social media).\n",
    "\t- .html, .img, .mp4, .mp3, .pdf, .doc, .ppt\n",
    "\t- social media, \n",
    "\t- NoSQL\n",
    "\t\n",
    "* Data Repositories:\n",
    "\t- databases, data warehouses, data lakes, data marts, BigData stores/warehouses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks:\n",
    "* Query Language: SQL\n",
    "* Programming Language: Py\n",
    "* Shell: Bash\n",
    "\n",
    "- gather, extract, transform, load\n",
    "- data wrangling, clean\n",
    "- data analysis, mining\n",
    "- data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Types of File Formats:\n",
    "\n",
    "* .csv: delimited text file formats\n",
    "* .tsv : tab-separated val's\n",
    "\t- used to store data as text\n",
    "\n",
    "* .xlsx: Microsoft Excel Open .XML Spreadsheet\n",
    "\t- a spreadsheet\n",
    "\t- rows, columns, cells\n",
    "\t- Structured.\n",
    "\t- secure\n",
    "* .xml : extensible markup language\n",
    "\t- readable by humans and machines\n",
    "\t- similar to .html\n",
    "\t- self-descriptive language\n",
    "\t- platform independent\n",
    "\t- prog lang independent\n",
    "* .pdf : Portable Document Format\n",
    "\t- viewed the same on any device\n",
    "\t- by Adobe\n",
    "* .json : JavaScript Object Notation\n",
    "\t- prog lang independent\n",
    "\t- easy to use\n",
    "\t- one of the best tools for sharing data\n",
    "\t- used to return data by many services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of Data:\n",
    "\n",
    "* Relational Databases:\n",
    "\t- business activities\n",
    "\t- M* SQL Server\n",
    "\t- Oracle\n",
    "\t- MySQL\n",
    "\t- IBM DB2\n",
    "\t\t- can be used for analysis, predictions\n",
    "\t\n",
    "* Flat Files:\n",
    "\t- store data in plain text\n",
    "\t- one record per line/row\n",
    "\t- maps to a single table\n",
    "\t- like .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spreadsheet files:\n",
    "\t- a special type of flat file\n",
    "\t- organizes data in a tabular format\n",
    "\t- .XLS, .XLSV\n",
    "\t- Google Sheets, Apple Numbers, LibreOffice\n",
    "\n",
    "* XML Files:\n",
    "\t- can support complex data structures (i.e. hierarchal)\n",
    "\t- online surveys, bank statements, etc. (unstructured data sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API and Web Services:\n",
    "\t- Application Program Interfaces (API)\n",
    "\t- can return data in plain text, such as XML, HTML, JSON.\n",
    "\t- req.web() [from users] \n",
    "\t- req.network() [API].\n",
    "\t- TW, FB APIs\n",
    "\t- Stock Market APIs\n",
    "\t- Data Lookup and Valid APIs\n",
    "\n",
    "* Web Scraping\n",
    "\t(a.k.a -- screen scraping, web harvesting, web data extraction)\n",
    "\t- extract data from unstructured sources\n",
    "\t- downloads specific data\n",
    "\t- apps like IDM do web scraping\n",
    "\t- BeautifulSoup, Scrapy, Pandas, Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Streams and Feeds:\n",
    "\t- Aggregating streams of data\n",
    "\t- flowing from,\n",
    "\t\t- IoT devices and apps,\n",
    "\t\t- GPS data from cars,\n",
    "\t\t- PC programs,\n",
    "\t\t- websites.\n",
    "\t- stock tickers for trading\n",
    "\t- video feeds for threat detection\n",
    "\t- web click feeds for monitoring\n",
    "\t- real-time flight events\n",
    "\t\t* APACHE Kafka, Spark, Storm\n",
    "\n",
    "* RSS (Really Simple Syndication) Feeds:\n",
    "\t- capturing updated data from forums and news sites.\n",
    "\t- data is constantly refreshed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages:\n",
    "\n",
    "#### Remarks:\n",
    "1) Query L: \n",
    "\t- accessing and manipulating data in a database\n",
    "\t- SQL\n",
    "2) Programming L:\n",
    "\t- Python, R, Java\n",
    "\t- developing apps\n",
    "3) Shell L:\n",
    "\t- ideal for repetitive operational tasks\n",
    "\t- Bash, PowerShell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details:\n",
    "* SQL = Structured Query Language\n",
    "\t- designed for accessing and manipulating info from mainly relational databases\n",
    "\t\n",
    "\t- Insert, update, delete records in a database\n",
    "\t- Create new databases, tables, views\n",
    "\t- Write stored procedures.\n",
    "\t\t- (call them for later use)\n",
    "\t\n",
    "\t* Portable, platform independent\n",
    "\t* can be used for querying data in a wide variety of databases\n",
    "\t* simple syntax\n",
    "\t* fewer lines of code\n",
    "\t* interpreter system\n",
    "\t* retrieve large data quick and efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python (Py):\n",
    "\t- pandas : \n",
    "\t\t- data cleaning, analysis\n",
    "\t- numpy, scipy : \n",
    "\t\t- statistics\n",
    "\t- beautifulsoup, scrapy : \n",
    "\t\t- web scraping\n",
    "\t- Matplotlib, Seaborn : \n",
    "\t\t- visualization\n",
    "\t- Opency : \n",
    "\t\t- image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Repositories:\n",
    "\n",
    "* Data repo's help to isolate data,\n",
    "\t* and make reporting and analytics more efficient and credible\n",
    "\t\t* while also serving as a data archive.\n",
    "\n",
    "#### Databases:\n",
    "- databases, data warehouses, Big Data stores...\n",
    "\t* Database:\n",
    "\t\t- collection of data for input, storage, search, retrieval and modification of data\n",
    "\t- DBMS: (Database Management System) \n",
    "\t\t- a set of programs for creating and maintaining the db, and storing, modifying and - extracting info from the db.\n",
    "\t\t* uses \"Querying\" function.\n",
    "\t\t\n",
    "\t\t- Factors like,\n",
    "\t\t\t- Data type, \n",
    "\t\t\t- data structure, \n",
    "\t\t\t- querying mechanisms, \n",
    "\t\t\t- latency req's, \n",
    "\t\t\t- transaction speeds, \n",
    "\t\t\t- intended use\n",
    "\t\t\t\t- governs the choice of database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RDBMS: (Relational DBs)\n",
    "\t\t- data is organized\n",
    "\t\t- tabular format, rows & columns\n",
    "\t\t- well-defined structure\n",
    "\t\t- optimized for data operations and querying\n",
    "\t\t\t* Standard tool: SQL \n",
    "\t\t\n",
    "\t* NoSQL: (Non-Relational Databases)\n",
    "\t* \"Not Only SQL\"\n",
    "\t\t- emerged in response,\n",
    "\t\t\t- to the Volume, speed and diversity of data generation\n",
    "\t\t\t- i.e. Cloud Computing, IoT, social media.\n",
    "\t\t- build for speed, flex, scale:\n",
    "\t\t- schema-less form of data.\n",
    "\t\t- Big Data Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Warehouses:\n",
    "* A type of data repo.\n",
    "\t- works as a central repo\n",
    "\t\t- that merges info coming from disparate sources and consolidates it through the  \n",
    "\t\t\t- extract, transform and load (ETL) process. \n",
    "\t\t\t\t- into one comprehensive db for analytics and BI.\n",
    "\n",
    "* Extract, Transform, Load (ETL) Process:\n",
    "\t- Extract Data \n",
    "\t\t- from different sources\n",
    "\t- Transform data\n",
    "\t\t- to clean, usable state.\n",
    "\t- Load Data\n",
    "\t\t- into the data repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Data Stores:\n",
    "* Distributed computational and storage infrastructure to \n",
    "\tstore, scale and process very large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Details on DB's\n",
    "* RDBMS:\n",
    "\t- rows -> records\n",
    "\t- columns - > attributes\n",
    "\n",
    "\t- based on flat files i.e. spreadsheets\n",
    "\t- ideal for optimized storage, retrieval, processing for LARGE volumes of data\n",
    "\t- relationships between tables\n",
    "\t- restrictions can be made\n",
    "\t* SQL / can retrieve millions of records in seconds\n",
    "\t\n",
    "\t* IBM DB2, Microsoft SQL Server, MySQL, Oracle Database, PostgreSQL\n",
    "\t* Amazon RDS, Google Cloud SQL, IBM DB2 Cloud, Oracle Cloud, SQL Azure \n",
    "\t\n",
    "\t- creating meaningful info\n",
    "\t- flexibility\n",
    "\t- minimize data redundancy \n",
    "\t- easy backup/recovery\n",
    "\t- ACID complient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "* ACID: \n",
    "\t- Atomicity\n",
    "\t- Consistency\n",
    "\t- Isolation\n",
    "\t- Durability\n",
    "\t\t\n",
    "* Suitable For:\n",
    "\t- OLTP application \n",
    "\t(Online Transaction Processing)\n",
    "\t- Data Warehouses\n",
    "\t- IoT solutions\n",
    "\t\n",
    "* Limitations:\n",
    "\t- works well for structured data only\n",
    "\t- merging is difficult\n",
    "\t- greater val than defined gets lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NoSQL DB:\n",
    "\t- not only SQL or non-SQL\n",
    "\t\n",
    "\t- scale, performance, ease of use\n",
    "\t- built for specific data models\n",
    "\t- not traditional row/column/table designed\n",
    "\t- schema-less / free-form storing\n",
    "\t\n",
    "\t* Key-val store:\n",
    "\t\t- key:attribute\n",
    "\t\t- no relationships\n",
    "\t\t- no multiple keys\n",
    "\t\t\t- Redis, Memcached, DynamoDB\n",
    "\n",
    "\t* Document-based:\n",
    "\t\t+ flexible indexing\n",
    "\t\t+ powerful ad hoc queries\n",
    "\t\t+ analytics over docs\n",
    "\t\t- complex queries\n",
    "\t\t- multi-op transactions\n",
    "\t\t\t- MongoDB, CouchDB, Cloudant, DocumentDB\n",
    "\t* Column-based:\n",
    "\t\t+ column family (groping of columns)\n",
    "\t\t+ easier, faster accessing/searches\n",
    "\t\t+ great for heavy write/read requests \n",
    "\t\t- running complex queries\n",
    "\t\t- change patterns frequently\n",
    "\t\t\t- Cassandra, HBase\n",
    "\t\t\n",
    "\t* Graph-based\n",
    "\t\t+ visualizing, interpreting, relationships\n",
    "\t\t+ social networks, network diagrams, product recommendations, access management (face unlock etc.)\n",
    "\t\t\t+ neo4j, cosmosDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Positives of NRDBMS vs. RDBMS\t\n",
    "\t+ ability to handle LARGE VOLS of data\n",
    "\t+ distributed system\n",
    "\t+ effective, efficient\n",
    "\n",
    "* RDBMS vs. \n",
    "\t* NOSQL :\n",
    "* typed / composed \n",
    "\t* schema-less\n",
    "* expensive \n",
    "\t* low-cost\n",
    "* ACID-compliance \n",
    "\t* not ACID. \n",
    "* mature, easy troubleshoot \n",
    "\t* new, can be tricky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Marts, Data Lakes, ETL, Data Pipelines:\n",
    "* Some data repos:\n",
    "\t- Data Warehouse:\n",
    "\t\t- multi-purpose storage\n",
    "\t\t- data has already gone through ETL process, ready to analysis/mining\n",
    "\n",
    "\t- Data Marts:\n",
    "\t\t- a specific DWH.\n",
    "\t\t- built for some purpose\n",
    "\t\t\t* its purpose is giving stakeholders the relevant data, when they need it.\n",
    "\t\t\t* restricted, isolation, security\n",
    "\n",
    "\t- Data Lakes:\n",
    "\t\t- storage repo\n",
    "\t\t- any RAW data\n",
    "\t\t- classified, tagged as metadata\n",
    "\t\t- * \"STAGING AREA\" of a DWH.\n",
    "\t\t- predictive, advanced analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ETL Process\n",
    "###### Summary:\n",
    "  - gather raw data\n",
    "    - extract relevant info\n",
    "    - clean, standardize, transform\n",
    "    - load into a data-repo\n",
    "\n",
    "###### Details:\n",
    "- Extract: \n",
    "  - raw data -> staging area\n",
    "    \n",
    "  - Batch Processing:\n",
    "    - move large data, at scheduled intervals\n",
    "    - * Blendo, Stitch\n",
    "  - Stream Processing:\n",
    "    - pull real-time data, transform mid-transit\n",
    "    - * Apache Samza, Storm and Kafka\n",
    "    \n",
    "- Transform\n",
    "  - standardize (km, dd/mm/yy...)\n",
    "  - remove NA, duplicates\n",
    "  - filter()\n",
    "  - enrich data (i.e. name A B = A, B)\n",
    "  - key-relationships\n",
    "  - data validations, rules\n",
    "    \n",
    "  - * Initial Loading:\n",
    "    - all data into repo\n",
    "  - * Incremental Loading:\n",
    "    - periodically update/modify\n",
    "  - * Full-refresh:\n",
    "    - erase, reload data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pipelines   \n",
    "* Data Pipeline:\n",
    "  - the whole journey of moving data\n",
    "  - includes ETL\n",
    "  - batch, stream data\n",
    "  * Apache Beam and Kafka, DataFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data\n",
    "\n",
    "#### Foundations of Big Data:\n",
    "  - Ernst and Young:\n",
    "    * big data refers to the dynamic, large, and disparate volumes of data being created by people, tools, and machines. It requires new, innovative and scalable technology to collect, host, and analytically process the vast amount of data gathered in order to drive real-time business insights that relate to consumers, risk, profit, performance, productivity management, and enhanced shareholder value.\n",
    "    \n",
    "##### 5V's:\n",
    "  - Velocity : extremely fast, never stops\n",
    "  - Volume : scale\n",
    "  - Variety : SQL, NoSQL, schema-less\n",
    "  - Veracity : quality, origin, consistency, completeness, integrity, ambiguity\n",
    "  - Value : profit, benefits, satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools for Big Data Analytics\n",
    "* Apache Hadoop, Hive, Spark.\n",
    "##### Hadoop: \n",
    "- distributed storage and processing of BD\n",
    "- Java-based\n",
    "- Node : \n",
    "  >a computer\n",
    "- Cluster : \n",
    "  >1 computer\n",
    "- reliable, scalable, cost-effective\n",
    "    \n",
    "##### Hive:\n",
    "- DWH\n",
    "- high latency\n",
    "+ ETL, data analysis\n",
    "+ SQL\n",
    "    \n",
    "##### Spark:\n",
    "- distributed data analytics framework \n",
    "- Analysis, Processing, ML, Data Integration, ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Data for Analysis\n",
    "\n",
    "- what info\n",
    "  - your goal?\n",
    "- which source\n",
    "- plan\n",
    "  - time frame\n",
    "  - volume, amount\n",
    "  - define dependencies and risks\n",
    "- methods\n",
    "- key considerations\n",
    "  - quality, security, privacy\n",
    "- for reliable data\n",
    "  - no errors\n",
    "  - accurate\n",
    "  - complete\n",
    "  - relevant\n",
    "  - accessible\n",
    "- data governance\n",
    "  - security, regulation, compliances\n",
    "- data privacy\n",
    "  - confidentiality, licences, compliance to regulations\n",
    "\n",
    "* right data =>\n",
    "  - allow looking at multiple perspectives\n",
    "  - credible&reliable findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources\n",
    "* Internal \n",
    "- External\n",
    "* Primary\n",
    "  - obtained directly from source\n",
    "  - internal (CRM, HR, workflow applications)\n",
    "  - external (surveys, interviews, discussions, observations, focus groups)\n",
    "- Secondary \n",
    "  - from existing sources\n",
    "  - external db's\n",
    "  - research articles, publications, internet (public)\n",
    "  - data collected from public external \n",
    "- Third-party\n",
    "  - purchased from aggregators who collect data\n",
    "\n",
    "* Sources\n",
    "  * Dynamic\n",
    "  * Diverse\n",
    "  * Continuously evolving\n",
    "\n",
    "  - Databases\n",
    "    - Cloud\n",
    "  - Web\n",
    "    - social media\n",
    "  - sensor data\n",
    "    - from smart apps, wearable devices\n",
    "  - data exchange\n",
    "    - 3rd party\n",
    "    - voluntary sharing of data \n",
    "  - surveys\n",
    "  - Census\n",
    "    - household data as wealth, income, population\n",
    "  - Interviews\n",
    "    - qualitative data\n",
    "  - Observation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Gather & Import Data\n",
    "\n",
    "- using queries (SQL)\n",
    "  - to extract data from SQL DB's (RDBMS)\n",
    "- NRDBMS can be queried using SQL(-like) query tools\n",
    "  - or specific querying tools i.e. \n",
    "      - CQL for Cassandra\n",
    "      - GraphQL for Neo4J\n",
    "\n",
    "- API's\n",
    "  - invoked from apps\n",
    "  - can be used for data validation\n",
    "\n",
    "- web scraping (screen scraping, web harvesting)\n",
    "  - download things like\n",
    "    - text, info, images, videos, music etc.\n",
    "\n",
    "- RSS feeds (ongoing refreshed data)\n",
    "  - i.e. forums\n",
    "\n",
    "- sensor data\n",
    "  - IoT devices, apps, GPS\n",
    "\n",
    "- Data Exchange platforms\n",
    "  - well-defined protocols\n",
    "  - security, governance\n",
    "  * AWS DataExchange\n",
    "  * Crunchbase\n",
    "  * Lotame\n",
    "  * Snowflake\n",
    "\n",
    "\n",
    "* Other Sources\n",
    "  - research&advisory firms; i.e.\n",
    "  + Forrester, Gartner, Business Insider\n",
    "  - agencies: market surveys, demographic studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data\n",
    "\n",
    "* Identified and Gathered Data =>\n",
    "  - Data Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Data (data munging)\n",
    "  - data exploration \n",
    "    - understand your data better @ use case\n",
    "  - transformation\n",
    "    - structuring\n",
    "      - change form & schema\n",
    "        - to i.e. combining RDBMS&Web APIs' data\n",
    "        - joins  \n",
    "          - combines columns \n",
    "        - unions\n",
    "          - combines rows\n",
    "    - normalizing\n",
    "      - cleaning \n",
    "      - improving \n",
    "      - reduce redundancy & inconsistency\n",
    "    - denormalizing\n",
    "      - combines data \n",
    "      - for faster querying\n",
    "    - cleaning (filtering)\n",
    "      - inaccuracies\n",
    "      - NAs\n",
    "      - nulls\n",
    "      - incomplete\n",
    "      - biases\n",
    "      - outliers\n",
    "    - enriching\n",
    "      - adding stuff to make it more meaningful\n",
    "        - points,\n",
    "        - relationships,\n",
    "        - visualizations\n",
    "    - validation\n",
    "      - check consistency, quality, security\n",
    "    - publishing\n",
    "  - documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools for Data Wrangling\n",
    "- Excel Power Query / Spreadsheets\n",
    "- OpenRefine\n",
    "  - open-source\n",
    "  - can import&export data\n",
    "    - json, tsv, csv, xls, xml (transformation)\n",
    "- Google DataPrep\n",
    "  - fully-managed service\n",
    "  - @ cloud\n",
    "  - smart\n",
    "- Watson Studio Refinery\n",
    "  - IBM Watson Studio\n",
    "  - smart\n",
    "  - has built-in features to discover, cleanse, transform d\n",
    "- Trifacta Wrangler\n",
    "  - export to excel, tableau, R\n",
    "  - collab features\n",
    "- Python\n",
    "  - Jupyter Notebook\n",
    "  - NumPy\n",
    "  - SciPy\n",
    "  - pandas\n",
    "    - data analysis\n",
    "    - merging, joining, transforming \n",
    "- R language\n",
    "  - Dplyr\n",
    "  - Data.table\n",
    "    - aggregate large data sets quickly\n",
    "  - jsonlite\n",
    "    - json parsing tool, @ web API interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING\n",
    "1) Inspection\n",
    "  - detect issues, errors\n",
    "  - data profiling\n",
    "  - data visualization\n",
    "2) Cleaning\n",
    "  - @ use case\n",
    "  - NA's -> bias & wrong results\n",
    "  - duplicates\n",
    "  - irrelevant data (filtering)\n",
    "  - make sure formats are same (looking at you, yy/dd/mm haha)\n",
    "  - outliers, bad skew\n",
    "3) Verification \n",
    "  - > run summary statistics\n",
    "    - to makes ure it is consistent w/ reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "### Important Terms\n",
    "* Statistics :\n",
    "  - collection, analysis, interpretation, presentation of quantitive data\n",
    "  - helps ensure that\n",
    "    - data = interpreted correctly\n",
    "    - relationships = meaningful\n",
    "* Sample : \n",
    "  - a representative selection drawn from a total population\n",
    "* Population : \n",
    "  - A discrete group of people or things that can be identified by at least one common char for purposes of data collection and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Statistics:\n",
    "#### Descriptive Statistics\n",
    "- summarizing info @ sample\n",
    "- present data\n",
    "- simpler interpretation of data\n",
    "- no conclusions/relationship\n",
    "- GOAL: making it easier to visualize the data w/o doing interpreting\n",
    "\n",
    "##### Common Measures of Descriptive Statistics:\n",
    "* Central Tendency Measures\n",
    "  - Mean : sum/n\n",
    "  - Median : the middle val\n",
    "    - unique to each dataset\n",
    "      - not affected by outliers\n",
    "  - Mode : val that happens most frequently\n",
    "\n",
    "* Dispersion\n",
    "  - measure of variablity\n",
    "  * Types of Dispersion:\n",
    "    * Variance\n",
    "      - defines how far away the data points fall from the center\n",
    "      - lower var > consistent\n",
    "      - higher var > dissimilar vals, higher % of extremes\n",
    "    * sd\n",
    "      - how tightly your data is clustered around the mean\n",
    "    * range\n",
    "      - â–²x between largest-smallest val\n",
    "\n",
    "* Skewness\n",
    "  - shows whether dist of vals is symmetrical @ central val or skewed left/right.\n",
    "  - can affect types of valid analyses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferential Statistics \n",
    "* (kinda like predictive analysis)\n",
    "- making inferences or generalizations @ population\n",
    "- hypothesis testing\n",
    "  - i.e. compare outcomes in control groups\n",
    "- confidence intervals\n",
    "  - creates a range of vals the actual population val is likely to fall within\n",
    "  - kind of like predicting the range.\n",
    "- regression analysis\n",
    "\n",
    "  * sas, SPSS, StatSoft\n",
    "  * Statistics & Data Mining \n",
    "    - allows for better decision-making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "### What?\n",
    "- Process of extracting knowledge from data\n",
    "- involves the use of pattern recognition technologies, statistical analysis, math.\n",
    "\n",
    "### Goal?\n",
    "* GOAL: \n",
    "  - identify correlations, patterns, variations\n",
    "    * Pattern Recognition:\n",
    "      - discovery of regularities/commonalities in data\n",
    "      - raw data -> use tools -> do analysis\n",
    "  - understand trends,\n",
    "    * Trends :\n",
    "      - general tendency to change over time\n",
    "  - predict probs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques:\n",
    "1) Descriptive Modeling :\n",
    "2) Diagnostic :\n",
    "3) Predictive :\n",
    "4) Prescriptive :\n",
    "\n",
    "  - Classification:\n",
    "      - classifying attributes into target categories\n",
    "  - Clustering:\n",
    "      - grouping data into clusters\n",
    "      - so they can be treated as groups\n",
    "  - Anomaly/Outlier Detection:\n",
    "      - finding !normal patterns\n",
    "  - Association Rule Mining:\n",
    "      - establishing a relationship @ two data E\n",
    "  - Sequential Patterns:\n",
    "      - tracing a series of events that take place in a sequence\n",
    "  - Affinity Grouping:\n",
    "      - Discovering co-occurrence in relationships\n",
    "  - Decision Trees:\n",
    "      - building classification models\n",
    "      - @ form tree w/ multiple branches\n",
    "      - each branch = a probable occurrence\n",
    "  - Regression:\n",
    "      - identifying nature @ relationship @ two vars\n",
    "      - which could be causal or correlational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining Tools&Software\n",
    "* Spreadsheets\n",
    "  - basic data mining tasks\n",
    "  - hosts data\n",
    "  - easy access/read\n",
    "  * Excel Add-ons:\n",
    "    - Data Mining Client, XLMiner, KnowledgeMiner\n",
    "* R-Lang\n",
    "  - tm\n",
    "    - text mining\n",
    "  - twitteR\n",
    "    - mining tweets\n",
    "  * RStudio\n",
    "* Python\n",
    "  - pandas\n",
    "    - upload data\n",
    "    - organize, sort\n",
    "    - mean, median, mode, range\n",
    "    - correlation, dist\n",
    "    - visualization\n",
    "  - numpy\n",
    "    - math computing\n",
    "    - data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* IBM SPSS Statistics\n",
    "  - SPSS : Statistical Package for Social Sciences\n",
    "  - used for text analytics, trend analysis, validation\n",
    "* IBM Watson Studio\n",
    "  - web/cloud/desktop app\n",
    "* SAS\n",
    "  - graphical workbench for data mining\n",
    "  - relationships, anomalies\n",
    "  - mine, transform, analyze, validate reliability\n",
    "  - big data\n",
    "  - high security "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Communicating and Sharing Data Analysis Findings\n",
    "- understand the problem\n",
    "- desired outcome\n",
    "- communicating the findings for decision-making\n",
    "- @ on how well others understand and trust your insights\n",
    "  - story, visualization, data prep.\n",
    "  - connect @ your audience:\n",
    "    - Who is my audience?\n",
    "    - What is important to them?\n",
    "    - What will help them trust me?\n",
    "  - probably a diverse group\n",
    "  - framed around the level of your audience, not all data\n",
    "    - tell a compelling story\n",
    "    - too much info is bad\n",
    "  - demonstrate that you understand the business\n",
    "  - reference your data\n",
    "  - reference your data, state your assumptions, organize your presentation, identify best format\n",
    "\n",
    "- credibbility, reference, data visualization, create a compelling story\n",
    "- trust, understanding, relatability, narrative @ visual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewpoints\n",
    "- Storytelling\n",
    "  - a critical skill\n",
    "  - tell a clear, concise, compelling story \n",
    "    - to convince people (stakeholders, consumers) to action\n",
    "- Filter your data to the best \n",
    "- give just enough data, not too complex\n",
    "- communicate effectively\n",
    "- a compelling story @ visuals\n",
    "  - build a connection\n",
    "\n",
    "    - Data has value through the stories that it tells!\n",
    "    - A presentation is not a data dump!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Data Visualization\n",
    "- graphs, charts, maps\n",
    "- goal : make data easy to comprehend, interpret, retain.\n",
    "- choose the best visualization\n",
    "  - What is the relationship that I am trying to establish?\n",
    "  - Do I want to compare multiple vals, such as the # of products sold, and revenues generated over the last three years?\n",
    "  - Do I need my audience to see the correlation (r) between two vars?\n",
    "  - Do I want to detect anomalies in data? (outliers?, skewness?)\n",
    "  - What is the question I'm trying to answer?\n",
    "  - Interactive visualization? (i.e. allowing the user to set the vars to create different visualization)\n",
    "  - What should be the key takeaway for my audience?\n",
    "  - What does my audience need to know?\n",
    "  - What are the questions they have?\n",
    "\n",
    "- Bar Charts\n",
    "  - great for comparing datasets\n",
    "- Column Charts\n",
    "  - side-by-side value compare. Show change over time\n",
    "- Pie Charts\n",
    "  - proportion of the sub-parts in @ to one another.\n",
    "- Line Charts\n",
    "  - trends\n",
    "  - how a data val is changing @ a continuous var\n",
    "- Dashboards\n",
    "  - organizes & displays reports from multiple data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for Data Visualization\n",
    "- Spreadsheets\n",
    "  - Excel\n",
    "  - a wide range of charts\n",
    "  - smart suggestions\n",
    "  - Google Sheets has collab features\n",
    "- Jupyter Notebook\n",
    "- Python libs\n",
    "  - Matplotlib : visualization\n",
    "  - Bokeh : interactive charts&plots\n",
    "  - Dash : interactive web-based visualizations, HTML&JS not a must\n",
    "- R-Studio \n",
    "  - visualization\n",
    "- R-Shiny\n",
    "  - R-package\n",
    "  - interactive web apps\n",
    "  - can be standalone\n",
    "- IBM Cognos Analytics\n",
    "  - end-to-end analytics solution\n",
    "  - forecasting \n",
    "  - conditional formatting (see dist, highlight outliers)\n",
    "- Tableau (& Looker)\n",
    "  - interactive graphs & charts\n",
    "  - dashboards, worksheets\n",
    "  - publish @ stories\n",
    "  - allows imports from Py and R\n",
    "- Microsoft Power BI\n",
    "  - cloud-based business analytics\n",
    "  - Microsoft\n",
    "  - speed & efficiency\n",
    "  - easy-to-use, drag&drop\n",
    "  - Excel, SQL, cloud-based data repo comp.\n",
    "  - secure, powerful, flexible\n",
    "\n",
    "- Consider ease of use and purpose to select the right tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Career Paths\n",
    "- Industry, government, academia.\n",
    "- 37.34 billion$ 2018 to expected 105.08 billion$ 2027\n",
    "  - Data Analyst Specialist Roles\n",
    "    - associate ... principal analyst\n",
    "    - experience\n",
    "  - Domain Specialist\n",
    "    - specialization in a specific domain\n",
    "    - HR, Marketing, Sales, Healthcare, Social Media Analyst...\n",
    "  - Analytics-enabled roles\n",
    "    - Project, Marketing, HR Managers\n",
    "  - Other Data Professionals\n",
    "    - Data Engineers, Data Scientists, Big Data Analytics, Business / BI Analytics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things Employees Look For\n",
    "- fill a need\n",
    "- integrity\n",
    "  - meet a deadline or get a right answer \n",
    "    - get the right info!\n",
    "- clear communication\n",
    "- SQL, R, Py\n",
    "- adapting to high change (dynamic & adaptable)\n",
    "- detail-oriented\n",
    "- over-achievers\n",
    "- think outside the box\n",
    "- trouble-shooters\n",
    "- problem solvers\n",
    "- good with numbers \n",
    "- know data & data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to R\n",
    "## About R.\n",
    "- open source\n",
    "- easy \n",
    "- community\n",
    "- interpreted \n",
    "- descriptive statistics\n",
    "- correlation analysis\n",
    "- hypothesis testing\n",
    "  - Testing if the mean values of two groups are statistically different.\n",
    "  - making inferences about a population parameter based on a sample of data\n",
    "     -  i.e. t-test\n",
    "- statistical inference\n",
    "- data visualization\n",
    "- ML and AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some R Functions\n",
    "- class(1L) : 'integer'\n",
    "- is.integer(1L) : TRUE\n",
    "- rm(<var>) : removes var from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "- character = strings and characters\n",
    "- Logical = boolean data (i.e. TRUE and FALSE)\n",
    "- Casting = as.numeric() or as.integer() ...\n",
    "- factors = \n",
    "  - using summary() is good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hakan\\anaconda3\\envs\\my_py3\\Lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"R_HOME\"] = f\"{os.environ['CONDA_PREFIX']}\\\\Lib\\\\R\"\n",
    "\n",
    "# enables the %%R magic, not necessary if you've already done this\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1]  1  2  3  4  5  6  7  8  9 10\n",
      " [1] 10  9  8  7  6  5  4  3  2  1\n",
      " [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n",
      "[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n",
      "[25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n",
      "[37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "print(c(1:10)) # 1 to 10\n",
    "print(c(10:1)) # 10 to 1\n",
    "1997 < 2000\n",
    "\n",
    "data = c(5:50)\n",
    "c(5:50)\n",
    "data > 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "   Length     Class      Mode \n",
      "        5 character character \n",
      "\n",
      "[[2]]\n",
      " Anime Comedy  Crime \n",
      "     2      2      1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "genre_vector = c(\"Comedy\", \"Anime\", \"Crime\", \"Comedy\", \"Anime\")\n",
    "genre_factor = factor(genre_vector)\n",
    "\n",
    "gv = summary(genre_vector)\n",
    "gf = summary(genre_factor)\n",
    "\n",
    "print(list(gv, gf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of factors\n",
    "- Nominal Categorical vars\n",
    "  - no implied order\n",
    "- Ordinal \n",
    "  - have ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very short      Short     Medium       Long  Very long \n",
      "         2          2          1          1          1 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "movielength_vector <- c(\"Very short\", \"Short\", \"Medium\", \"Short\", \"Long\", \"Very short\", \"Very long\")\n",
    "\n",
    "movielength_factor <- factor (\n",
    "    movielength_vector,\n",
    "    ordered = TRUE,\n",
    "    levels = c(\"Very short\", \"Short\", \"Medium\", \"Long\", \"Very long\")\n",
    ")\n",
    "\n",
    "summary(movielength_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "     [,1]         [,2]         [,3]    \n",
      "[1,] \"Very short\" \"Long\"       \"Short\" \n",
      "[2,] \"Short\"      \"Very short\" \"Medium\"\n",
      "[3,] \"Medium\"     \"Very long\"  \"Short\" \n",
      "[4,] \"Short\"      \"Very short\" \"Long\"  \n",
      "\n",
      "[[2]]\n",
      "[1] \"Long\"\n",
      "\n",
      "[[3]]\n",
      "[1] \"Short\"  \"Medium\" \"Short\"  \"Long\"  \n",
      "\n",
      "[[4]]\n",
      "     [,1]         [,2]         [,3]        \n",
      "[1,] \"Very short\" \"Short\"      \"Very long\" \n",
      "[2,] \"Short\"      \"Long\"       \"Very short\"\n",
      "[3,] \"Medium\"     \"Very short\" \"Short\"     \n",
      "\n",
      "[[5]]\n",
      "     [,1]         [,2]         [,3]        \n",
      "[1,] \"Very short\" \"Short\"      \"Medium\"    \n",
      "[2,] \"Short\"      \"Long\"       \"Very short\"\n",
      "[3,] \"Very long\"  \"Very short\" \"Short\"     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: In matrix(movielength_factor, nrow = 3, ncol = 3) :\n",
       "  data length [7] is not a sub-multiple or multiple of the number of rows [3]\n",
       "2: In matrix(movielength_factor, nrow = 3, ncol = 3, byrow = TRUE) :\n",
       "  data length [7] is not a sub-multiple or multiple of the number of rows [3]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "movie_array = array(movielength_vector, dim = c(4,3))\n",
    "movie_matrix = matrix(movielength_factor, nrow = 3, ncol = 3)\n",
    "movie_matrix_byrow = matrix(movielength_factor, nrow = 3, ncol = 3, byrow = TRUE)\n",
    "\n",
    "print(list(\n",
    "    movie_array, \n",
    "    movie_array[1,2], \n",
    "    movie_array[,3],\n",
    "    movie_matrix,\n",
    "    movie_matrix_byrow\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Akira\"      \"Toy Story\"  \"Room\"       \"The Wave\"   \"Whiplash\"  \n",
      "[6] \"Star Wars\"  \"The Ring\"   \"The Artist\" \"Jumanji\"   \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#lets first create a vector of nine movies\n",
    "movie_vector <- c(\"Akira\", \"Toy Story\", \"Room\", \"The Wave\", \"Whiplash\",\n",
    "                  \"Star Wars\", \"The Ring\", \"The Artist\", \"Jumanji\")\n",
    "movie_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1]        [,2]         [,3]       \n",
      "[1,] \"Akira\"     \"Whiplash\"   \"Jumanji\"  \n",
      "[2,] \"Toy Story\" \"Star Wars\"  \"Akira\"    \n",
      "[3,] \"Room\"      \"The Ring\"   \"Toy Story\"\n",
      "[4,] \"The Wave\"  \"The Artist\" \"Room\"     \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "movie_array <- array(movie_vector, dim = c(4,3))\n",
    "movie_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n",
      "[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n",
      "[31] 15.0 21.4\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mpg = mtcars$mpg\n",
    "mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$name\n",
      "[1] \"Juan\"\n",
      "\n",
      "$age\n",
      "[1] 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "x = c(25, 35, 40, 50, 75)\n",
    "mean(x)\n",
    "\n",
    "employee = list(name = \"Juan\", age = 30)\n",
    "employee[\"age\"] = 35\n",
    "employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"222222222klijsljksfalsjkfajklssfkklijsljksfalsjkfajklssfkasskjsdfasskfklijsljksfalsjkfajklssfkasskjsdfasskfklijsljksfalsjkfajklssfkasskjsdfasskfklijsljksfalsjkfajklssfkasskjsdfasskSfklijsljksfalsjkfajklssfkasskjsdfasskfklijsljksfalsjkfajklssfkasskjsdfasskfasskjsdfasskf asfas asfafa safaf\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "thing = \"111111111klijsljkÅŸfalÅŸjkfajklÅŸsfkklijsljkÅŸfalÅŸjkfajklÅŸsfkasÅŸkjÅŸdfasÅŸkfklijsljkÅŸfalÅŸjkfajklÅŸsfkasÅŸkjÅŸdfasÅŸkfklijsljkÅŸfalÅŸjkfajklÅŸsfkasÅŸkjÅŸdfasÅŸkfklijsljkÅŸfalÅŸjkfajklÅŸsfkasÅŸkjÅŸdfasÅŸkSfklijsljkÅŸfalÅŸjkfajklÅŸsfkasÅŸkjÅŸdfasÅŸkfklijsljkÅŸfalÅŸjkfajklÅŸsfkasÅŸkjÅŸdfasÅŸkfasÅŸkjÅŸdfasÅŸkf asfas asfafa safaf\"\n",
    "nchar(thing) # number of chars\n",
    "toupper(thing) # converts every char to upper chars\n",
    "nchar(toupper(thing))\n",
    "tolower(thing)\n",
    "chartr(\"1\", \"2\", thing) # char translation (changes 1 to 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"A\"            \"summary\"      \"is\"           \"a\"            \"short\"       \n",
      " [6] \"statement\"    \"that\"         \"summarizes\"   \"or\"           \"informs\"     \n",
      "[11] \"the\"          \"audience\"     \"of\"           \"the\"          \"main\"        \n",
      "[16] \"ideas\"        \"of\"           \"a\"            \"longer\"       \"piece\"       \n",
      "[21] \"of\"           \"writing.\"     \"Essentially,\" \"the\"          \"summary\"     \n",
      "[26] \"is\"           \"a\"            \"short\"        \"version\"      \"of\"          \n",
      "[31] \"a\"            \"longer\"       \"text.\"        \"The\"          \"size\"        \n",
      "[36] \"of\"           \"a\"            \"summary\"      \"can\"          \"vary\"        \n",
      "[41] \"based\"        \"on\"           \"the\"          \"type\"         \"of\"          \n",
      "[46] \"writing,\"     \"but\"          \"most\"         \"often\"        \"they\"        \n",
      "[51] \"are\"          \"no\"           \"longer\"       \"than\"         \"a\"           \n",
      "[56] \"page.\"       \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "summary = \"A summary is a short statement that summarizes or informs the audience of the main ideas of a longer piece of writing. Essentially, the summary is a short version of a longer text. The size of a summary can vary based on the type of writing, but most often they are no longer than a page.\"\n",
    "\n",
    "char_list = strsplit(summary, \" \")\n",
    "word_list = unlist(char_list) \n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"a a a a a a A are audience based but can Essentially, ideas informs is is longer longer longer main most no of of of of of of often on or page. piece short short size statement summarizes summary summary summary text. than that the the the the The they type vary version writing, writing.\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sorted_list = sort(word_list)\n",
    "paste(sorted_list, collapse = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \" a page.\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sub_string = substr(summary, start = 2, stop = 47) # a sub string starting from 3rd word ends with 46th.\n",
    "trimws(sub_string) # trims white spaces (trimws) from the word, from beginning and end.\n",
    "\n",
    "library(stringr)\n",
    "str_sub(summary, -8, -1) # takes the sub string starting from -8 to -1\n",
    "# str_sub is basically a more powerful version of substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"The\"             \"Artist\"          \"is\"              \"a\"              \n",
      " [5] \"2011\"            \"French\"          \"romantic\"        \"comedy-drama\"   \n",
      " [9] \"in\"              \"the\"             \"style\"           \"of\"             \n",
      "[13] \"a\"               \"black-and-white\" \"silent\"          \"film.\"          \n",
      "[17] \"It\"              \"was\"             \"written,\"        \"directed,\"      \n",
      "[21] \"and\"             \"co-edited\"       \"by\"              \"Michel\"         \n",
      "[25] \"Hazanavicius,\"   \"produced\"        \"by\"              \"Thomas\"         \n",
      "[29] \"Langmann\"        \"and\"             \"starred\"         \"Jean\"           \n",
      "[33] \"Dujardin\"        \"and\"             \"BÃ©rÃ©nice\"      \"Bejo.\"          \n",
      "[37] \"The\"             \"story\"           \"takes\"           \"place\"          \n",
      "[41] \"in\"              \"Hollywood,\"      \"between\"         \"1927\"           \n",
      "[45] \"and\"             \"1932,\"           \"and\"             \"focuses\"        \n",
      "[49] \"on\"              \"the\"             \"relationship\"    \"of\"             \n",
      "[53] \"an\"              \"older\"           \"silent\"          \"film\"           \n",
      "[57] \"star\"            \"and\"             \"a\"               \"rising\"         \n",
      "[61] \"young\"           \"actress\"         \"as\"              \"silent\"         \n",
      "[65] \"cinema\"          \"falls\"           \"out\"             \"of\"             \n",
      "[69] \"fashion\"         \"and\"             \"is\"              \"replaced\"       \n",
      "[73] \"by\"              \"the\"             \"talkies.\"       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Read 75 items\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "readme <- \"C:/Users/hakan/Downloads/test.txt\"\n",
    "\n",
    "my_data <- scan(file = readme, what = \"\")\n",
    "my_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 4 \n",
      "5 7 5 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "word_factor = factor(my_data)\n",
    "summary(word_factor) # gives frequency of words\n",
    "\n",
    "data2 = c(1,1,1,1,1,2,2,2,2,2,2,2,4,4,4,4,4) \n",
    "data2_f = factor(data2) \n",
    "summary(data2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference of 12961 days\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "as.Date(\"27/06/04\", \"%d/%m/%y\") \n",
    "# [1] \"2004-06-27\"\n",
    "as.Date(\"1994/06/27\") - as.Date(\"1959/01/01\") \n",
    "# Time difference of 12961 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"2024-02-15\" \"2024-03-15\" \"2024-04-15\" \"2024-05-15\" \"2024-06-15\"\n",
      " [6] \"2024-07-15\" \"2024-08-15\" \"2024-09-15\" \"2024-10-15\" \"2024-11-15\"\n",
      "[11] \"2024-12-15\" \"2025-01-15\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "date = Sys.Date() \n",
    "\n",
    "Sys.Date()\n",
    "# [1] \"2024-02-13\"\n",
    "date() \n",
    "# [1] \"Tue Feb 13 14:51:49 2024\"\n",
    "Sys.time()\n",
    "# [1] \"2024-02-13 14:52:00 +03\"\n",
    "\n",
    "weekdays(date) \n",
    "# [1] \"Tuesday\"\n",
    "months(date) \n",
    "# [1] \"February\"\n",
    "quarters(date) \n",
    "# [1] \"Q1\"\n",
    "\n",
    "seq(date, by = \"month\", length.out=12) # gives a sequence of dates with 1 month between every for up to 12 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "dates = seq(date, by = \"day\", length.out = 365)\n",
    "dates_char = format(dates, \"%d-%m-%Y\")\n",
    "writeLines(dates_char, \"dates.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Found error!\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "tryCatch(\n",
    "    for (i in 1:3) {\n",
    "        print(i + \"a\")\n",
    "    }\n",
    "    , error = function(e) print(\"Found error!\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Oops, something went wrong!\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "tryCatch(10 + \"a\", error = function(a)\n",
    "            print(\"Oops, something went wrong!\")  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The quick rec fax jumpec aver the lazy cat.\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "string = \"The quick red fox jumped over the lazy dog.\"\n",
    "chartr(\"dog\", \"cat\", string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%R` not found.\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "25 > 15 | 99 >= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 50 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Murder</th><th scope=col>Assault</th><th scope=col>UrbanPop</th><th scope=col>Rape</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Alabama</th><td>13.2</td><td>236</td><td>58</td><td>21.2</td></tr>\n",
       "\t<tr><th scope=row>Alaska</th><td>10.0</td><td>263</td><td>48</td><td>44.5</td></tr>\n",
       "\t<tr><th scope=row>Arizona</th><td> 8.1</td><td>294</td><td>80</td><td>31.0</td></tr>\n",
       "\t<tr><th scope=row>Arkansas</th><td> 8.8</td><td>190</td><td>50</td><td>19.5</td></tr>\n",
       "\t<tr><th scope=row>California</th><td> 9.0</td><td>276</td><td>91</td><td>40.6</td></tr>\n",
       "\t<tr><th scope=row>Colorado</th><td> 7.9</td><td>204</td><td>78</td><td>38.7</td></tr>\n",
       "\t<tr><th scope=row>Connecticut</th><td> 3.3</td><td>110</td><td>77</td><td>11.1</td></tr>\n",
       "\t<tr><th scope=row>Delaware</th><td> 5.9</td><td>238</td><td>72</td><td>15.8</td></tr>\n",
       "\t<tr><th scope=row>Florida</th><td>15.4</td><td>335</td><td>80</td><td>31.9</td></tr>\n",
       "\t<tr><th scope=row>Georgia</th><td>17.4</td><td>211</td><td>60</td><td>25.8</td></tr>\n",
       "\t<tr><th scope=row>Hawaii</th><td> 5.3</td><td> 46</td><td>83</td><td>20.2</td></tr>\n",
       "\t<tr><th scope=row>Idaho</th><td> 2.6</td><td>120</td><td>54</td><td>14.2</td></tr>\n",
       "\t<tr><th scope=row>Illinois</th><td>10.4</td><td>249</td><td>83</td><td>24.0</td></tr>\n",
       "\t<tr><th scope=row>Indiana</th><td> 7.2</td><td>113</td><td>65</td><td>21.0</td></tr>\n",
       "\t<tr><th scope=row>Iowa</th><td> 2.2</td><td> 56</td><td>57</td><td>11.3</td></tr>\n",
       "\t<tr><th scope=row>Kansas</th><td> 6.0</td><td>115</td><td>66</td><td>18.0</td></tr>\n",
       "\t<tr><th scope=row>Kentucky</th><td> 9.7</td><td>109</td><td>52</td><td>16.3</td></tr>\n",
       "\t<tr><th scope=row>Louisiana</th><td>15.4</td><td>249</td><td>66</td><td>22.2</td></tr>\n",
       "\t<tr><th scope=row>Maine</th><td> 2.1</td><td> 83</td><td>51</td><td> 7.8</td></tr>\n",
       "\t<tr><th scope=row>Maryland</th><td>11.3</td><td>300</td><td>67</td><td>27.8</td></tr>\n",
       "\t<tr><th scope=row>Massachusetts</th><td> 4.4</td><td>149</td><td>85</td><td>16.3</td></tr>\n",
       "\t<tr><th scope=row>Michigan</th><td>12.1</td><td>255</td><td>74</td><td>35.1</td></tr>\n",
       "\t<tr><th scope=row>Minnesota</th><td> 2.7</td><td> 72</td><td>66</td><td>14.9</td></tr>\n",
       "\t<tr><th scope=row>Mississippi</th><td>16.1</td><td>259</td><td>44</td><td>17.1</td></tr>\n",
       "\t<tr><th scope=row>Missouri</th><td> 9.0</td><td>178</td><td>70</td><td>28.2</td></tr>\n",
       "\t<tr><th scope=row>Montana</th><td> 6.0</td><td>109</td><td>53</td><td>16.4</td></tr>\n",
       "\t<tr><th scope=row>Nebraska</th><td> 4.3</td><td>102</td><td>62</td><td>16.5</td></tr>\n",
       "\t<tr><th scope=row>Nevada</th><td>12.2</td><td>252</td><td>81</td><td>46.0</td></tr>\n",
       "\t<tr><th scope=row>New Hampshire</th><td> 2.1</td><td> 57</td><td>56</td><td> 9.5</td></tr>\n",
       "\t<tr><th scope=row>New Jersey</th><td> 7.4</td><td>159</td><td>89</td><td>18.8</td></tr>\n",
       "\t<tr><th scope=row>New Mexico</th><td>11.4</td><td>285</td><td>70</td><td>32.1</td></tr>\n",
       "\t<tr><th scope=row>New York</th><td>11.1</td><td>254</td><td>86</td><td>26.1</td></tr>\n",
       "\t<tr><th scope=row>North Carolina</th><td>13.0</td><td>337</td><td>45</td><td>16.1</td></tr>\n",
       "\t<tr><th scope=row>North Dakota</th><td> 0.8</td><td> 45</td><td>44</td><td> 7.3</td></tr>\n",
       "\t<tr><th scope=row>Ohio</th><td> 7.3</td><td>120</td><td>75</td><td>21.4</td></tr>\n",
       "\t<tr><th scope=row>Oklahoma</th><td> 6.6</td><td>151</td><td>68</td><td>20.0</td></tr>\n",
       "\t<tr><th scope=row>Oregon</th><td> 4.9</td><td>159</td><td>67</td><td>29.3</td></tr>\n",
       "\t<tr><th scope=row>Pennsylvania</th><td> 6.3</td><td>106</td><td>72</td><td>14.9</td></tr>\n",
       "\t<tr><th scope=row>Rhode Island</th><td> 3.4</td><td>174</td><td>87</td><td> 8.3</td></tr>\n",
       "\t<tr><th scope=row>South Carolina</th><td>14.4</td><td>279</td><td>48</td><td>22.5</td></tr>\n",
       "\t<tr><th scope=row>South Dakota</th><td> 3.8</td><td> 86</td><td>45</td><td>12.8</td></tr>\n",
       "\t<tr><th scope=row>Tennessee</th><td>13.2</td><td>188</td><td>59</td><td>26.9</td></tr>\n",
       "\t<tr><th scope=row>Texas</th><td>12.7</td><td>201</td><td>80</td><td>25.5</td></tr>\n",
       "\t<tr><th scope=row>Utah</th><td> 3.2</td><td>120</td><td>80</td><td>22.9</td></tr>\n",
       "\t<tr><th scope=row>Vermont</th><td> 2.2</td><td> 48</td><td>32</td><td>11.2</td></tr>\n",
       "\t<tr><th scope=row>Virginia</th><td> 8.5</td><td>156</td><td>63</td><td>20.7</td></tr>\n",
       "\t<tr><th scope=row>Washington</th><td> 4.0</td><td>145</td><td>73</td><td>26.2</td></tr>\n",
       "\t<tr><th scope=row>West Virginia</th><td> 5.7</td><td> 81</td><td>39</td><td> 9.3</td></tr>\n",
       "\t<tr><th scope=row>Wisconsin</th><td> 2.6</td><td> 53</td><td>66</td><td>10.8</td></tr>\n",
       "\t<tr><th scope=row>Wyoming</th><td> 6.8</td><td>161</td><td>60</td><td>15.6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 50 Ã— 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Murder & Assault & UrbanPop & Rape\\\\\n",
       "  & <dbl> & <int> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\tAlabama & 13.2 & 236 & 58 & 21.2\\\\\n",
       "\tAlaska & 10.0 & 263 & 48 & 44.5\\\\\n",
       "\tArizona &  8.1 & 294 & 80 & 31.0\\\\\n",
       "\tArkansas &  8.8 & 190 & 50 & 19.5\\\\\n",
       "\tCalifornia &  9.0 & 276 & 91 & 40.6\\\\\n",
       "\tColorado &  7.9 & 204 & 78 & 38.7\\\\\n",
       "\tConnecticut &  3.3 & 110 & 77 & 11.1\\\\\n",
       "\tDelaware &  5.9 & 238 & 72 & 15.8\\\\\n",
       "\tFlorida & 15.4 & 335 & 80 & 31.9\\\\\n",
       "\tGeorgia & 17.4 & 211 & 60 & 25.8\\\\\n",
       "\tHawaii &  5.3 &  46 & 83 & 20.2\\\\\n",
       "\tIdaho &  2.6 & 120 & 54 & 14.2\\\\\n",
       "\tIllinois & 10.4 & 249 & 83 & 24.0\\\\\n",
       "\tIndiana &  7.2 & 113 & 65 & 21.0\\\\\n",
       "\tIowa &  2.2 &  56 & 57 & 11.3\\\\\n",
       "\tKansas &  6.0 & 115 & 66 & 18.0\\\\\n",
       "\tKentucky &  9.7 & 109 & 52 & 16.3\\\\\n",
       "\tLouisiana & 15.4 & 249 & 66 & 22.2\\\\\n",
       "\tMaine &  2.1 &  83 & 51 &  7.8\\\\\n",
       "\tMaryland & 11.3 & 300 & 67 & 27.8\\\\\n",
       "\tMassachusetts &  4.4 & 149 & 85 & 16.3\\\\\n",
       "\tMichigan & 12.1 & 255 & 74 & 35.1\\\\\n",
       "\tMinnesota &  2.7 &  72 & 66 & 14.9\\\\\n",
       "\tMississippi & 16.1 & 259 & 44 & 17.1\\\\\n",
       "\tMissouri &  9.0 & 178 & 70 & 28.2\\\\\n",
       "\tMontana &  6.0 & 109 & 53 & 16.4\\\\\n",
       "\tNebraska &  4.3 & 102 & 62 & 16.5\\\\\n",
       "\tNevada & 12.2 & 252 & 81 & 46.0\\\\\n",
       "\tNew Hampshire &  2.1 &  57 & 56 &  9.5\\\\\n",
       "\tNew Jersey &  7.4 & 159 & 89 & 18.8\\\\\n",
       "\tNew Mexico & 11.4 & 285 & 70 & 32.1\\\\\n",
       "\tNew York & 11.1 & 254 & 86 & 26.1\\\\\n",
       "\tNorth Carolina & 13.0 & 337 & 45 & 16.1\\\\\n",
       "\tNorth Dakota &  0.8 &  45 & 44 &  7.3\\\\\n",
       "\tOhio &  7.3 & 120 & 75 & 21.4\\\\\n",
       "\tOklahoma &  6.6 & 151 & 68 & 20.0\\\\\n",
       "\tOregon &  4.9 & 159 & 67 & 29.3\\\\\n",
       "\tPennsylvania &  6.3 & 106 & 72 & 14.9\\\\\n",
       "\tRhode Island &  3.4 & 174 & 87 &  8.3\\\\\n",
       "\tSouth Carolina & 14.4 & 279 & 48 & 22.5\\\\\n",
       "\tSouth Dakota &  3.8 &  86 & 45 & 12.8\\\\\n",
       "\tTennessee & 13.2 & 188 & 59 & 26.9\\\\\n",
       "\tTexas & 12.7 & 201 & 80 & 25.5\\\\\n",
       "\tUtah &  3.2 & 120 & 80 & 22.9\\\\\n",
       "\tVermont &  2.2 &  48 & 32 & 11.2\\\\\n",
       "\tVirginia &  8.5 & 156 & 63 & 20.7\\\\\n",
       "\tWashington &  4.0 & 145 & 73 & 26.2\\\\\n",
       "\tWest Virginia &  5.7 &  81 & 39 &  9.3\\\\\n",
       "\tWisconsin &  2.6 &  53 & 66 & 10.8\\\\\n",
       "\tWyoming &  6.8 & 161 & 60 & 15.6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 50 Ã— 4\n",
       "\n",
       "| <!--/--> | Murder &lt;dbl&gt; | Assault &lt;int&gt; | UrbanPop &lt;int&gt; | Rape &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| Alabama | 13.2 | 236 | 58 | 21.2 |\n",
       "| Alaska | 10.0 | 263 | 48 | 44.5 |\n",
       "| Arizona |  8.1 | 294 | 80 | 31.0 |\n",
       "| Arkansas |  8.8 | 190 | 50 | 19.5 |\n",
       "| California |  9.0 | 276 | 91 | 40.6 |\n",
       "| Colorado |  7.9 | 204 | 78 | 38.7 |\n",
       "| Connecticut |  3.3 | 110 | 77 | 11.1 |\n",
       "| Delaware |  5.9 | 238 | 72 | 15.8 |\n",
       "| Florida | 15.4 | 335 | 80 | 31.9 |\n",
       "| Georgia | 17.4 | 211 | 60 | 25.8 |\n",
       "| Hawaii |  5.3 |  46 | 83 | 20.2 |\n",
       "| Idaho |  2.6 | 120 | 54 | 14.2 |\n",
       "| Illinois | 10.4 | 249 | 83 | 24.0 |\n",
       "| Indiana |  7.2 | 113 | 65 | 21.0 |\n",
       "| Iowa |  2.2 |  56 | 57 | 11.3 |\n",
       "| Kansas |  6.0 | 115 | 66 | 18.0 |\n",
       "| Kentucky |  9.7 | 109 | 52 | 16.3 |\n",
       "| Louisiana | 15.4 | 249 | 66 | 22.2 |\n",
       "| Maine |  2.1 |  83 | 51 |  7.8 |\n",
       "| Maryland | 11.3 | 300 | 67 | 27.8 |\n",
       "| Massachusetts |  4.4 | 149 | 85 | 16.3 |\n",
       "| Michigan | 12.1 | 255 | 74 | 35.1 |\n",
       "| Minnesota |  2.7 |  72 | 66 | 14.9 |\n",
       "| Mississippi | 16.1 | 259 | 44 | 17.1 |\n",
       "| Missouri |  9.0 | 178 | 70 | 28.2 |\n",
       "| Montana |  6.0 | 109 | 53 | 16.4 |\n",
       "| Nebraska |  4.3 | 102 | 62 | 16.5 |\n",
       "| Nevada | 12.2 | 252 | 81 | 46.0 |\n",
       "| New Hampshire |  2.1 |  57 | 56 |  9.5 |\n",
       "| New Jersey |  7.4 | 159 | 89 | 18.8 |\n",
       "| New Mexico | 11.4 | 285 | 70 | 32.1 |\n",
       "| New York | 11.1 | 254 | 86 | 26.1 |\n",
       "| North Carolina | 13.0 | 337 | 45 | 16.1 |\n",
       "| North Dakota |  0.8 |  45 | 44 |  7.3 |\n",
       "| Ohio |  7.3 | 120 | 75 | 21.4 |\n",
       "| Oklahoma |  6.6 | 151 | 68 | 20.0 |\n",
       "| Oregon |  4.9 | 159 | 67 | 29.3 |\n",
       "| Pennsylvania |  6.3 | 106 | 72 | 14.9 |\n",
       "| Rhode Island |  3.4 | 174 | 87 |  8.3 |\n",
       "| South Carolina | 14.4 | 279 | 48 | 22.5 |\n",
       "| South Dakota |  3.8 |  86 | 45 | 12.8 |\n",
       "| Tennessee | 13.2 | 188 | 59 | 26.9 |\n",
       "| Texas | 12.7 | 201 | 80 | 25.5 |\n",
       "| Utah |  3.2 | 120 | 80 | 22.9 |\n",
       "| Vermont |  2.2 |  48 | 32 | 11.2 |\n",
       "| Virginia |  8.5 | 156 | 63 | 20.7 |\n",
       "| Washington |  4.0 | 145 | 73 | 26.2 |\n",
       "| West Virginia |  5.7 |  81 | 39 |  9.3 |\n",
       "| Wisconsin |  2.6 |  53 | 66 | 10.8 |\n",
       "| Wyoming |  6.8 | 161 | 60 | 15.6 |\n",
       "\n"
      ],
      "text/plain": [
       "               Murder Assault UrbanPop Rape\n",
       "Alabama        13.2   236     58       21.2\n",
       "Alaska         10.0   263     48       44.5\n",
       "Arizona         8.1   294     80       31.0\n",
       "Arkansas        8.8   190     50       19.5\n",
       "California      9.0   276     91       40.6\n",
       "Colorado        7.9   204     78       38.7\n",
       "Connecticut     3.3   110     77       11.1\n",
       "Delaware        5.9   238     72       15.8\n",
       "Florida        15.4   335     80       31.9\n",
       "Georgia        17.4   211     60       25.8\n",
       "Hawaii          5.3    46     83       20.2\n",
       "Idaho           2.6   120     54       14.2\n",
       "Illinois       10.4   249     83       24.0\n",
       "Indiana         7.2   113     65       21.0\n",
       "Iowa            2.2    56     57       11.3\n",
       "Kansas          6.0   115     66       18.0\n",
       "Kentucky        9.7   109     52       16.3\n",
       "Louisiana      15.4   249     66       22.2\n",
       "Maine           2.1    83     51        7.8\n",
       "Maryland       11.3   300     67       27.8\n",
       "Massachusetts   4.4   149     85       16.3\n",
       "Michigan       12.1   255     74       35.1\n",
       "Minnesota       2.7    72     66       14.9\n",
       "Mississippi    16.1   259     44       17.1\n",
       "Missouri        9.0   178     70       28.2\n",
       "Montana         6.0   109     53       16.4\n",
       "Nebraska        4.3   102     62       16.5\n",
       "Nevada         12.2   252     81       46.0\n",
       "New Hampshire   2.1    57     56        9.5\n",
       "New Jersey      7.4   159     89       18.8\n",
       "New Mexico     11.4   285     70       32.1\n",
       "New York       11.1   254     86       26.1\n",
       "North Carolina 13.0   337     45       16.1\n",
       "North Dakota    0.8    45     44        7.3\n",
       "Ohio            7.3   120     75       21.4\n",
       "Oklahoma        6.6   151     68       20.0\n",
       "Oregon          4.9   159     67       29.3\n",
       "Pennsylvania    6.3   106     72       14.9\n",
       "Rhode Island    3.4   174     87        8.3\n",
       "South Carolina 14.4   279     48       22.5\n",
       "South Dakota    3.8    86     45       12.8\n",
       "Tennessee      13.2   188     59       26.9\n",
       "Texas          12.7   201     80       25.5\n",
       "Utah            3.2   120     80       22.9\n",
       "Vermont         2.2    48     32       11.2\n",
       "Virginia        8.5   156     63       20.7\n",
       "Washington      4.0   145     73       26.2\n",
       "West Virginia   5.7    81     39        9.3\n",
       "Wisconsin       2.6    53     66       10.8\n",
       "Wyoming         6.8   161     60       15.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "View(USArrests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP Request and REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
